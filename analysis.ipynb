{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw ensemble analys\n",
    "# id,arrival_time,start_service_times,start_service_times,completion_time\n",
    "# time,event_id,event_type,timing,length_event_list,length_queue1,length_queue2,in_service1,in_service2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of file path based on Parameters:\n",
    "#mean_interarrival,mean_machine_time_1,mean_machine_time_2,max_queue_1,max_queue_2,time_units,std_machine_1\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class Parameter:\n",
    "    mean_interarrival:float\n",
    "    mean_machine_time_1:float\n",
    "    mean_machine_time_2:float\n",
    "    max_queue_1:int\n",
    "    max_queue_2:int\n",
    "    time_units:str\n",
    "    std_machine_1:float\n",
    "\n",
    "def get_parameter(s):\n",
    "    s = s.split(',')\n",
    "    \n",
    "    return Parameter(\n",
    "        mean_interarrival=float(s[0]),\n",
    "        mean_machine_time_1=float(s[1]),\n",
    "        mean_machine_time_2=float(s[2]),\n",
    "        max_queue_1=int(s[3]),\n",
    "        max_queue_2=int(s[4]),\n",
    "        time_units=s[5],\n",
    "        std_machine_1=float(s[6])\n",
    "    )\n",
    "\n",
    "# the file path should look like this: data/mean_interarrival_60.0/max_queue_1_9223372036854775807/max_queue_2_4/mean_machine_time_125.0\n",
    "def get_file_path_from_parameters(p, n):\n",
    "    states_files, entities_files= [],[]\n",
    "    root_path = f\"data/mean_interarrival_{p.mean_interarrival}/max_queue_1_{p.max_queue_1}/max_queue_2_{p.max_queue_2}/mean_machine_time_1{p.mean_machine_time_1}/mean_machine_time_2{p.mean_machine_time_2}\"\n",
    "    for i in range(1,n+1):\n",
    "        states_files.append(f\"{root_path}/seed{i}/state.csv\")\n",
    "        entities_files.append(f\"{root_path}/seed{i}/entities.csv\")\n",
    "    return states_files, entities_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_parameter(\"60.0, 25.0, 59.0, 9223372036854775807,4, \\\"minutes\\\", 7.185832891717325\")\n",
    "states_file_path , entities_file_path = get_file_path_from_parameters(p,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all states files and get ensemble data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_ensemble_data(states_file_path):\n",
    "    states = []\n",
    "    for file_path in states_file_path[:2]:\n",
    "        states.append(pd.read_csv(file_path, skiprows=9))\n",
    "    # create group the data base on \"time\" column with time step of 10, filter on timing == \"before\"\n",
    "    ensemble_states = [s[(s[\"timing\"] == \"before\") & (s[\"event_type\"] == \"Arrival\")] for s in states]    # drop the event_type and timing columns\n",
    "    ensemble_states = [s.drop(columns=[\"event_type\", \"timing\"]) for s in ensemble_states]\n",
    "    ensemble_states = [s.groupby(np.arange(len(s))//10).mean() for s in ensemble_states]\n",
    "\n",
    "    return states, ensemble_states\n",
    "\n",
    "states, ensemble_states = get_ensemble_data(states_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: [time, event_id, length_event_list, length_queue1, length_queue2, in_service1, in_service2]\n",
       " Index: []]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
